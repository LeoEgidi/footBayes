% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compare_foot.R
\name{compare_foot}
\alias{compare_foot}
\title{Compare Football Models using Accuracy and Brier Score}
\usage{
compare_foot(models, test_data, metric = c("accuracy", "brier", "pseudoR2"))
}
\arguments{
\item{models}{A named list of fitted model objects (of class \code{stanFoot}), each representing a football model.}

\item{test_data}{A data frame containing the test dataset, with columns:
\itemize{
  \item \code{home_team}: Home team's name (character string).
  \item \code{away_team}: Away team's name (character string).
  \item \code{homegoals}: Goals scored by the home team (integer >= 0).
  \item \code{awaygoals}: Goals scored by the away team (integer >= 0).
}}

\item{metric}{A character vector specifying the metrics to use for comparison. Options are:
\itemize{
  \item \code{"accuracy"}: Computes the accuracy of each model.
  \item \code{"brier"}: Computes the Brier score of each model.
  \item \code{"pseudoR2"}: Computes the McFadden's Pseudo $R^2$ for each model.
}
Default is \code{c("accuracy", "brier", "pseudoR2")}, computing both metrics.}
}
\value{
A data frame containing the metric values for each model.
}
\description{
Compares multiple football models based on specified metrics (accuracy and/or Brier score), using a test dataset.
}
\details{
The function extracts predictions from each model and computes the chosen metrics on the test dataset. For accuracy, it computes the proportion of correct predictions. For the Brier score, it computes the mean squared difference between the predicted probabilities and the actual outcomes.
}
\examples{
\dontrun{

Load the dataset
data("italy")
italy <- as_tibble(italy)

# Filter and select the required columns
italy_2021_test <- italy \%>\%
  select(Season, home, visitor, hgoal, vgoal) \%>\%
  filter(Season == "2021")

# Set the first 340 rows as they are and replace hgoal and vgoal with NA for remaining rows
italy_2021 <- italy_2021 \%>\%
  mutate(
    hgoal = ifelse(row_number() > 340, NA, hgoal),
    vgoal = ifelse(row_number() > 340, NA, vgoal)
  )

# Create a list of unique teams
teams <- unique(italy_2021$home)
n_rows <- 20

# Create a fake ranking
ranking <- data.frame(
  periods = rep(1, n_rows),
  team = sample(teams, n_rows, replace = FALSE),
  rank_points = sample(0:60, n_rows, replace = FALSE)
)

ranking <- ranking \%>\%
  arrange(periods, desc(rank_points))

# Fit a model using stan_foot
fit_with_ranking <- stan_foot(
  data = italy_2021,
  model = "diag_infl_biv_pois",
  predict = 40,
  ranking = ranking,
  prior_par = list(
    ability = student_t(4, 0, NULL),
    ability_sd = cauchy(0, 3),
    home = normal(1, 10)
  ),
  home_effect = TRUE,
  norm_method = "mad",
  iter = 1000,
  chains = 2,
  cores = 2,
  control = list(adapt_delta = 0.95, max_treedepth = 15)
)

# Print a summary of the model fit
print(fit_with_ranking$fit)

# Create another fake ranking
ranking2 <- data.frame(
  periods = rep(1, n_rows),
  team = sample(teams, n_rows, replace = FALSE),
  rank_points = sample(0:100, n_rows, replace = FALSE)
)

ranking2 <- ranking2 \%>\%
  arrange(periods, desc(rank_points))

# Fit another model with a different ranking
fit_with_ranking2 <- stan_foot(
  data = italy_2021,
  model = "biv_pois",
  predict = 40,
  ranking = ranking2,
  prior_par = list(
    ability = student_t(4, 0, NULL),
    ability_sd = cauchy(0, 3),
    home = normal(1, 10)
  ),
  home_effect = TRUE,
  norm_method = "mad",
  iter = 1000,
  chains = 2,
  cores = 2,
  control = list(adapt_delta = 0.95, max_treedepth = 15)
)

# Prepare the test data for comparison
data("italy")
italy <- as_tibble(italy)

italy_2021_test <- italy \%>\%
  select(Season, home, visitor, hgoal, vgoal) \%>\%
  filter(Season == "2021")

italy_2021_test <- italy_2021_test[341:380,]

# Compare the two models
compare_models <- list(model1 = fit_with_ranking,
                       model2 = fit_with_ranking2)

compare_foot(compare_models, test_data = italy_2021_test)
}
}
